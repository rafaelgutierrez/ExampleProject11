{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import time\n",
    "# mlibrerias modelos score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tpot.builtins import StackingEstimator, ZeroCount\n",
    "findspark.init('/usr/hdp/2.5.0.0-1245/spark2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.sql import HiveContext\n",
    "hive_context = HiveContext(sc)\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hive_context.sql(\"show databases\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataf_1 = hive_context.sql(\"select * from dev.rafael_traf_fcdr_2d\")\n",
    "all_datam_1 = hive_context.sql(\"select * from dev.rafael_traf_mcdr_2d\")\n",
    "all_datam = all_datam_1.toPandas()\n",
    "all_dataf = all_dataf_1.toPandas()\n",
    "#all_datam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns_m = ['rec_type',\n",
    "                   'called_number',\n",
    "                   'called_imei',\n",
    "                   'called_imsi',\n",
    "                   'cllng_number',\n",
    "                   'cllng_imei',\n",
    "                   'cllng_imsi',\n",
    "                   'call_duration',\n",
    "                   'cause_for_term',\n",
    "                   'exchange_id',\n",
    "                   'fcalled_ci',\n",
    "                   'fcllng_ci',\n",
    "                   'in_asig_route',\n",
    "                   'in_route', \n",
    "                   'lcalled_ci',\n",
    "                   'lcllng_ci',\n",
    "                   'org_called_num',\n",
    "                   'out_route',\n",
    "                   'int_rec_number',\n",
    "                   'int_charg_ind',\n",
    "                   'rdirect_imsi',\n",
    "                   'rdirect_number',\n",
    "                   'start_time', \n",
    "                   'end_time',\n",
    "                   'basic_serv_type',\n",
    "                   'facility_usage',\n",
    "                   'camel_call_ref',\n",
    "                   'camel_exch_id',\n",
    "                   'cllng_first_lac',\n",
    "                   'clled_first_lac',\n",
    "                   'emer_call_cat',\n",
    "                   'clln_number_ton',\n",
    "                   'dial_number_ton',\n",
    "                   'cellid_lac_a',\n",
    "                   'cellid_lac_b',\n",
    "                   'cdr_date', \n",
    "                   'pais',\n",
    "                   '_c2',\n",
    "                   '_c3']\n",
    "new_columns_f = ['abonado_origen',\n",
    "'called_number',\n",
    "'cllng_number',\n",
    "'abonado_destino_transformado',\n",
    "'abonado_destino_original',\n",
    "'fecha',\n",
    "'hora_inicio',\n",
    "'call_duration',\n",
    "'tipo_cdr',\n",
    "'ruta_entrante',\n",
    "'ruta_saliente',\n",
    "'x_alias_central',\n",
    "'cod_localidad_origen',\n",
    "'cod_localidad_destino',\n",
    "'cod_municipio_origen',\n",
    "'cod_municipio_destino',\n",
    "'cod_area_geografica_origen',\n",
    "'cod_area_geografica_destino',\n",
    "'cod_pais_origen',\n",
    "'cod_pais_destino',\n",
    "'portabilidad_numerica',\n",
    "'fecha_migracion',\n",
    "'start_time',\n",
    "'fecha_fin',\n",
    "'cdr_date',\n",
    "'pais',\n",
    "'_c2',\n",
    "'_c3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataf.columns = new_columns_f\n",
    "all_datam.columns = new_columns_m\n",
    "\n",
    "\n",
    "\n",
    "columns_selection = ['cllng_number','called_number','start_time',\n",
    "                     'call_duration','cdr_date']\n",
    "\n",
    "all_datam_final = all_datam[columns_selection]\n",
    "all_dataf_final = all_dataf[columns_selection]\n",
    "\n",
    "all_datam_final.dtypes\n",
    "all_dataf_final.dtypes\n",
    "#ll_ldi_fraud_input.dtypes\n",
    "all_ldi_fraud_input = pd.concat([all_datam_final,all_dataf_final], axis=0, ignore_index=True)\n",
    "all_data=all_ldi_fraud_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attrib_fraud_score(all_data):\n",
    "    import pandas as pd\n",
    "    import datetime   \n",
    "    output_final=pd.DataFrame()\n",
    "    \n",
    "    all_data['call_duration']=pd.to_numeric(all_data['call_duration'])\n",
    "    all_data.cdr_date=pd.to_datetime(all_data.cdr_date)\n",
    "    all_data['start_time_1']= all_data['start_time'].astype(str)\n",
    "    all_data['start_time_1']=pd.to_datetime(all_data['start_time_1'],format='%Y%m%d%H%M%S',errors ='coerce' )\n",
    "    \n",
    "    \n",
    "    #table_attributes['tot_time']=all_data.groupby(['cllng_number'])['call_duration'].sum()\n",
    "    #table_attributes['avg_time']=all_data.groupby(['cllng_number'])['call_duration'].mean()\n",
    "    #table_attributes['T_unique_numbers']=all_data.groupby(['cllng_number']).called_number.nunique()\n",
    "    #table_attributes['tot_calls']=all_data.groupby(['cllng_number'])['cllng_number'].count()\n",
    "    #table_attributes['stdev_duration_calls']=all_data.groupby(['cllng_number'])['call_duration'].std()\n",
    "    #table_attributes['scattered_calls']=all_data.groupby(['cllng_number','call_type'])['start_time_1'].std()\n",
    "\n",
    "    \"\"\"  last day attributes creation must be calcultated for each number  with the \n",
    "    following guidelines:  took  last record time (start_time),  then develop\n",
    "    all attributes 24 hours before this time\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" last day attributes creation must be calcultated for each number  with the \n",
    "    following guidelines:  took  last record time (start_time),  then develop\n",
    "    all attributes 24 hours before this time\n",
    "    \"\"\"\n",
    "    bad_attributes=pd.DataFrame()\n",
    "    \n",
    "    bad_attributes['cllng_number']=all_data['cllng_number'].unique()\n",
    "    #test_0=last_24hr_cdr['cllng_number'].unique()\n",
    "    #output_final=pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "    ## funcion para crear columnas planas \n",
    "    def flatten_cols(df):\n",
    "        df.columns = [\n",
    "                '_'.join(tuple(map(str, t))).rstrip('_') \n",
    "                for t in df.columns.values\n",
    "                ]\n",
    "        return df\n",
    "    ## end of function \n",
    "        \n",
    "   # end function Hour of the day\n",
    "    \n",
    "    def hr_day_func(ts):\n",
    "        hora_dia= ts.hour\n",
    "        return hora_dia  \n",
    "    \n",
    "    # end function to get day hour\n",
    "\n",
    "   # lista =  bad_attributes['cllng_number'].unique()\n",
    "    \n",
    "\n",
    "    \n",
    "    #  lista = telecom_List\n",
    "     #k=lista[0]\n",
    "    #import numpy as np\n",
    "   \n",
    "    #all_data['cllng_number'] = pd.to_numeric(all_data['cllng_number'])\n",
    "    #all_data['cllng_number']= all_data['cllng_number'].astype(np.int64)\n",
    "\t\n",
    "\n",
    "        #     TELEFONO\tOPERADOR\tFECHA_DETECCION\n",
    "        #    15673069\tTELECOM\t2018-05-06\n",
    "        # 3187544004,TELECOM,1/30/2018\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        #celular=all_data[all_data['cllng_number'] == 15688540]\n",
    "        #celular  = celular[ celular['cdr_date'] <= '2018-06-11'] \n",
    "        # num_unicos['numero']                            \n",
    "        \n",
    "        #\n",
    "        \n",
    "    weeks_before_2 = all_data['cdr_date'].max()- datetime.timedelta(days=15)\n",
    "    ## ya se  realiza la extraccion paa las ultimas dos horas\n",
    "    #hours_before_2 = row['FECHA_DETECCION']- datetime.timedelta(hours=3)\n",
    "    # celular dataframe with info from last 2 weeks\n",
    "    #celular  = celular[ celular['start_time_1'] >= weeks_before_2]\n",
    "    \n",
    "    yesterday = all_data.cdr_date.max() - datetime.timedelta(days=1)  \n",
    "    \n",
    "    # dataframe with cdr data from their last day \n",
    "    last_2day_cdr=all_data.query('cdr_date >= @yesterday' ) \n",
    "    \n",
    "    \n",
    "    table_attributes=pd.DataFrame()\n",
    "    table_attributes['tot_time']=all_data.groupby(['cllng_number'])['call_duration'].sum()\n",
    "    table_attributes['avg_time']=all_data.groupby(['cllng_number'])['call_duration'].mean()\n",
    "    table_attributes['T_unique']=all_data.groupby(['cllng_number'])['called_number'].nunique()\n",
    "    table_attributes['tot_cal']=all_data.groupby(['cllng_number'])['cllng_number'].count()\n",
    "    table_attributes['stdev_dur_cal']=all_data.groupby(['cllng_number'])['call_duration'].std()\n",
    "    \n",
    "    \n",
    "    #table_attributes=pd.DataFrame()\n",
    "    # get calculated from total last day     \n",
    "    table_attributes['tot_time_2d']=last_2day_cdr.groupby(['cllng_number'])['call_duration'].sum()\n",
    "    table_attributes['avg_time_2d']=last_2day_cdr.groupby(['cllng_number'])['call_duration'].mean()\n",
    "    table_attributes['T_unique_2d']=last_2day_cdr.groupby(['cllng_number'])['called_number'].nunique()\n",
    "    table_attributes['tot_cal_2d']=last_2day_cdr.groupby(['cllng_number'])['cllng_number'].count()\n",
    "    table_attributes['stdev_dur_cal_2ld']=last_2day_cdr.groupby(['cllng_number'])['call_duration'].std()\n",
    "    #   table_attributes['scattered_cal_ld']=last_day_cdr.groupby(['cllng_number','call_type'])['start_time_1'].std()\n",
    "    \n",
    "    # get attributes from last 24 hours\n",
    "    \n",
    "    T_24hr = all_data.start_time_1.max() - datetime.timedelta(hours = 24)  \n",
    "\n",
    "    \n",
    "    last_24hr_cdr=all_data.query('start_time_1 >= @T_24hr' ) \n",
    "    # function for get hour delta \n",
    "    def hr_func(ts):\n",
    "        if last_24hr_cdr.start_time_1.max().date() == ts.date():\n",
    "            return  last_24hr_cdr.start_time_1.max().hour-ts.hour\n",
    "        else:    return  last_24hr_cdr.start_time_1.max().hour + (24-ts.hour)\n",
    "        \n",
    "     \n",
    "    def quarter_time_func(ts):\n",
    "        return  (celular_hour.start_time_1.max()-ts).seconds/60\n",
    "        \n",
    "        \n",
    "          \n",
    "    \n",
    "    def hr_group_func(ts):\n",
    "        if ts <= 4: return 4\n",
    "        elif ts>4 and ts<= 8: return 8\n",
    "        elif ts>8 and ts<=12: return 12\n",
    "        elif ts>12 and ts <=16 : return 16\n",
    "        elif ts>16 and ts<=20: return 20 \n",
    "        else :\n",
    "            return 24  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # end function Hour of the day\n",
    "    # rafael 23 de octubre de 2018\n",
    "    pd.options.mode.chained_assignment = None  # default='warn\n",
    "    last_24hr_cdr['hora_0']= last_24hr_cdr['start_time_1'].apply(hr_func)\n",
    "    last_24hr_cdr['hora']= last_24hr_cdr['hora_0'].apply(hr_group_func)\n",
    "    last_24hr_cdr['hora_dia']= last_24hr_cdr['start_time_1'].apply(hr_day_func)\n",
    "    attributes_hora_dia=pd.DataFrame()\n",
    "    attributes_hora_dia['sum_call_time_Hdia_out']=last_24hr_cdr.groupby(['cllng_number','hora_dia'])['call_duration'].sum()\n",
    "    attributes_hora_dia['tot_call_Hdia_out']=last_24hr_cdr.groupby(['cllng_number','hora_dia'])['call_duration'].count()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # test=attributes_day.unstack(level=1)\n",
    "    #test_1=test.unstack(level=1)\n",
    "    # data fram with tot call and sum of call time by day hour for  last 24 hours\n",
    "    t_attr_dia=attributes_hora_dia.unstack(level=1)\n",
    "    \n",
    "    output_celular=pd.DataFrame()   \n",
    "    #flatten_cols(test)\n",
    "    flatten_cols(t_attr_dia)\n",
    "        \n",
    "    \"\"\" \n",
    "    Section to get attributes last 2 hours\n",
    "\n",
    "    \"\"\"\n",
    "    test_quarter = pd.DataFrame()\n",
    "    import tqdm\n",
    "\n",
    "\n",
    "    num_unicos =pd.DataFrame()\n",
    "    num_unicos['numero']= last_24hr_cdr['cllng_number'].unique()\n",
    "    \n",
    "    #num_unicos['numero']=pd.to_numeric(num_unicos['numero'])\n",
    "    #all_data.dtypeslast_24hr_cdr\n",
    "    \n",
    "    for index,row in num_unicos.iterrows():\n",
    "        #print(index/17081)\n",
    "        celular=pd.DataFrame()\n",
    "        \n",
    "        time.sleep(0.01)\n",
    "        celular=last_24hr_cdr[last_24hr_cdr['cllng_number'] == row['numero']]  \n",
    "        #celular=last_24hr_cdr[last_24hr_cdr['cllng_number'] == '3168456745']\n",
    "        \n",
    "        #celular  = celular[ celular['cdr_date'] <= row['FECHA_DETECCION']]\n",
    "        celular['call_duration']=pd.to_numeric(celular['call_duration'])\n",
    "        celular.cdr_date=pd.to_datetime(celular.cdr_date)\n",
    "        celular.cdr_date.max()\n",
    "        \n",
    "        celular_ult_horas = pd.DataFrame()\n",
    "        time_ventana=celular['start_time_1'].max() - datetime.timedelta(hours=2)\n",
    "        celular_ult_horas =celular[ celular['start_time_1'] >= time_ventana ] \n",
    "                           \n",
    "        #print(row['numero'],len(celular))\n",
    "        \n",
    "        if len(celular_ult_horas)==0: \n",
    "            continue \n",
    "        celular_ult_horas['call_duration']=pd.to_numeric(celular_ult_horas['call_duration'])\n",
    "        celular_ult_horas.cdr_date=pd.to_datetime(celular_ult_horas.cdr_date)\n",
    "\n",
    "        celular_ult_horas['call_duration']=pd.to_numeric(celular_ult_horas['call_duration'])\n",
    "        celular_ult_horas.cdr_date=pd.to_datetime(celular_ult_horas.cdr_date)\n",
    "        celular_ult_horas['start_time_1']= celular_ult_horas['start_time'].astype(str)\n",
    "        celular_ult_horas['start_time_1']=pd.to_datetime(celular_ult_horas['start_time_1'],format='%Y%m%d%H%M%S')\n",
    "        \n",
    "        #agg_10m = df.groupby(pd.Grouper(freq='10Min')).aggregate(numpy.sum)\n",
    "\n",
    "        #celular_ult_horas['agg_10m'] = celular_ult_horas.groupby(pd.Grouper(key= '', freq='15Min'))\n",
    "        ult_2_horas = pd.DataFrame()\n",
    "        ult_2_horas['15min']=  celular_ult_horas.groupby(['cllng_number', pd.Grouper(key='start_time_1', freq='15Min')])['call_duration'].sum()\n",
    "        ult_2_horas.reset_index(level=0, inplace=True)\n",
    "        ult_2_horas['time'] = ult_2_horas.index\n",
    "        #ult_2_horas.query('cllng_number==3005192893')\n",
    "        \n",
    "        #def flatten_cols(df):\n",
    "        #    df.columns = [\n",
    "        #        '_'.join(tuple(map(str, t))).rstrip('_') \n",
    "        #        for t in df.columns.values\n",
    "        #        ]\n",
    "        #return df\n",
    "    \n",
    "            \n",
    "       #test.start_time.max().minuter-ts.minutehour    \n",
    "    \n",
    "        def quarter_time_func(ts):\n",
    "            return  (celular.start_time_1.max()-ts).seconds/60\n",
    "    \n",
    "        # funcion para calcular los ultimas horas en promedios de 15 minutos\n",
    "    \n",
    "        def hr_group_func(ts):\n",
    "            if ts <= 15: return 15\n",
    "            elif ts>15 and ts<= 30: return 30\n",
    "            elif ts>30 and ts<=45: return 45\n",
    "            elif ts>45 and ts <=60 : return 60\n",
    "            elif ts>60 and ts<=75: return 75 \n",
    "            elif ts>75 and ts<=90: return 90\n",
    "            elif ts>90 and ts<=105: return 105\n",
    "            else :\n",
    "                return 120\n",
    "            \n",
    "            \n",
    "        celular_ult_horas['minutes']=  celular_ult_horas['start_time_1'].apply(quarter_time_func)   \n",
    "        celular_ult_horas['quarter']=  celular_ult_horas['minutes'].apply(hr_group_func)\n",
    "     \n",
    "     \n",
    "        table_attributes_ult_horas=pd.DataFrame()\n",
    "        # get calculated from total last day     \n",
    "        table_attributes_ult_horas['tot_time']=celular_ult_horas.groupby(['cllng_number','quarter'])['call_duration'].sum()\n",
    "        table_attributes_ult_horas['avg_time']=celular_ult_horas.groupby(['cllng_number','quarter'])['call_duration'].mean()\n",
    "        table_attributes_ult_horas['T_unique']=celular_ult_horas.groupby(['cllng_number','quarter'])['called_number'].nunique()\n",
    "        table_attributes_ult_horas['tot_cal']=celular_ult_horas.groupby(['cllng_number','quarter'])['cllng_number'].count()\n",
    "        # table_attributes_ult_horas['stdev_dur_cal_ld']=celular_ult_horas.groupby(['cllng_number'])['call_duration'].std()\n",
    "\n",
    "        test_quarter_part=table_attributes_ult_horas.unstack(level=1)\n",
    "        flatten_cols(test_quarter_part)\n",
    "        \n",
    "        test_quarter= pd.concat([test_quarter,test_quarter_part], axis=0, sort = True )\n",
    "        \n",
    "    \"\"\" \n",
    "    end Section to get attributes last 2 hours\n",
    "    see  results on test_quarter table\n",
    "    \"\"\"\n",
    "        \n",
    "        #table_attributes.columns\n",
    "        # test_1.columns = test_1.columns.tolist()\n",
    "        \n",
    "        # case empty table attributes 3196422755\n",
    "        # case   several days 3002161926\n",
    "        \n",
    "        # start if\n",
    "        \n",
    "        #if len(table_attributes) == 0:  \n",
    "        #    s=pd.DataFrame(columns=['tot_time_ld', 'avg_time_ld', 'T_unique_ld', 'tot_cal_ld',\n",
    "        #                            'stdev_dur_cal_ld'], index=[str(row['TELEFONO'])])\n",
    "        #    table_attributes=s\n",
    "        #    #table_attributes=table_attributes.append(s, ignore_index = False)\n",
    "        #    output_celular=pd.concat([table_attributes.reset_index(drop=True), test.reset_index(drop=True)], axis=1)\n",
    "        #    # change the index value \n",
    "        #    as_list = output_celular.index.tolist()\n",
    "        #    idx = as_list.index(0)\n",
    "        #    as_list[idx] = row['TELEFONO']\n",
    "        #    output_celular.index = as_list\n",
    "        #    output_celular['Call_num'] = output_celular.index\n",
    "        #else:\n",
    "            # table_attributes_1=table_attributes.unstack(level=2)\n",
    "            #flatten_cols(table_attributes)\n",
    "    output_celular=pd.merge(table_attributes,t_attr_dia, right_index=True, left_index=True, sort = True)\n",
    "    output_celular=pd.merge(output_celular,test_quarter, right_index=True, left_index=True,how = \"left\", sort = True)\n",
    "    #output_celular=pd.merge(output_celular,table_attributes_ult_horas, right_index=True, left_index=True)\n",
    "    #table_attributes_ult_horas    #output_celular=pd.merge(output_celular,table_attributes_ult_horas, right_index=True, left_index=True)\n",
    "            \n",
    "            \n",
    "    output_celular['Call_num'] = output_celular.index\n",
    "            # output_final=output_final.append(output_celular, sort =True)\n",
    "               \n",
    "        #if k==lista[0]:\n",
    "        #    print(k)\n",
    "        #    output_final=output_celular\n",
    "        #else:\n",
    "        #print(k)\n",
    "            #output_final_0 = pd.concat(list(output_final.align(output_celular)), ignore_index=True)\n",
    "    #output_final = pd.concat([output_final,output_celular], axis=0, ignore_index=True)\n",
    "\n",
    "        \n",
    "       \n",
    "    del table_attributes ,test_quarter   \n",
    "\n",
    "\n",
    "    #output_final=output_final.join(output_celular,on='Call_num',\n",
    "    #                                    lsuffix='_left', rsuffix='_right')\n",
    "    \n",
    "\n",
    "    return output_celular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resultados = get_attrib_fraud_score(all_ldi_fraud_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_celular.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_datam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_remove=['tot_time_2d'\n",
    "#,'avg_time_2d'\n",
    "#,'T_unique_2d'\n",
    "#,'tot_cal_2d'\n",
    "#,'stdev_dur_cal_2ld'\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_testing = resultados.drop(cols_remove, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exported_pipeline = make_pipeline(\n",
    "#    StackingEstimator(estimator=BernoulliNB(alpha=1.0, fit_prior=True)),\n",
    "#    PolynomialFeatures(degree=2, include_bias=False, interaction_only=False),\n",
    "#    ZeroCount(),\n",
    "#    RandomForestClassifier(bootstrap=True, criterion=\"entropy\",\n",
    "#                           max_features=0.4, min_samples_leaf=12,\n",
    "#                           min_samples_split=3, n_estimators=100)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "# load the model from local\n",
    "ruta = '/home/dataloaderusr/fraude_model_19mar.sav'\n",
    "loaded_model = pickle.load(open(ruta, 'rb'))\n",
    "#result = loaded_model.score(X_test, Y_test)\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring\n",
    "#ruta_score = 'c:/data/trafico_ldi/scoring_input/score_input_dic_1.csv'\n",
    "#input_score = pd.read_csv(ruta_score , sep=',', dtype=np.float64)\n",
    "cols_remove=['tot_time_2d'\n",
    ",'avg_time_2d'\n",
    ",'T_unique_2d'\n",
    ",'tot_cal_2d'\n",
    ",'stdev_dur_cal_2ld'\n",
    ", 'Call_num'\n",
    "             \n",
    "]\n",
    "resultados_1 = resultados.fillna(0) \n",
    "features_testing =  resultados_1.drop(cols_remove, axis=1)\n",
    "\n",
    "\n",
    "result_score = loaded_model.predict_proba(features_testing)\n",
    "#sum(result_score)\n",
    "#import pandas as pd\n",
    "salida_marcacion = pd.DataFrame(result_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output fraude score \n",
    "salida_marcacion.to_csv('/home/dataloaderusr/output_fraude.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
